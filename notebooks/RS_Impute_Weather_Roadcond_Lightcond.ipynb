{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seattle Traffic Collision Data\n",
    "### Rebecca Stewart\n",
    "\n",
    "## Add census area, neighborhood and impute weather, lightcond and roadcond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Keeps our notebooks clean \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# New imports\n",
    "from datetime import datetime\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I installed geopandas from a conda prompt after having problem using !pip install geopandas from a notebook\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The only change between the master and the following is that my data files are in a data directory not within the notebook folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE DATA FROM THE LOCAL CSV FILE\n",
    "local_file_name  = \"../data/collisions_orig.csv\"\n",
    "df_collisions  = pd.read_csv(local_file_name , parse_dates=[\"INCDTTM\"])\n",
    "df_locations_xy = pd.read_csv('../data/location_xy.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220436, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the starting shape\n",
    "df_collisions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save column list to restore column order after merge\n",
    "column_list = df_collisions.columns\n",
    "column_list = column_list.append(pd.Index(['fe_exists']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220436, 38)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the old X,Y and replace with the ones in location_xy.csv if they exist, otherwise, will be nan\n",
    "df_collisions.drop(columns=['X','Y'],inplace=True,errors='ignore')   # get these from the location_xy.csv file\n",
    "df_collisions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.merge(df_collisions, df_locations_xy, on='LOCATION', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220436, 41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do some sanity checks\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the original order of columns\n",
    "df_new = df_new[column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    216059\n",
       "0      4377\n",
       "Name: fe_exists, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['fe_exists'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220436   220436\n"
     ]
    }
   ],
   "source": [
    "new_keys = list(df_new['INCKEY'])\n",
    "col_keys = list(df_collisions['INCKEY'])\n",
    "print(f\"{len(new_keys)}   {len(col_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns deemed unnecessary\n",
    "df_new.drop(['EXCEPTRSNCODE', 'EXCEPTRSNDESC', 'STATUS', 'REPORTNO', 'SEGLANEKEY', 'CROSSWALKKEY', 'INCKEY','COLDETKEY'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to lowercase\n",
    "df_new.columns = df_new.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x', 'y', 'objectid', 'addrtype', 'intkey', 'location', 'severitycode',\n",
       "       'severitydesc', 'collisiontype', 'personcount', 'pedcount',\n",
       "       'pedcylcount', 'vehcount', 'injuries', 'seriousinjuries', 'fatalities',\n",
       "       'incdate', 'incdttm', 'junctiontype', 'sdot_colcode', 'sdot_coldesc',\n",
       "       'inattentionind', 'underinfl', 'weather', 'roadcond', 'lightcond',\n",
       "       'pedrownotgrnt', 'sdotcolnum', 'speeding', 'st_colcode', 'st_coldesc',\n",
       "       'hitparkedcar', 'fe_exists'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7189\n",
      "7189\n"
     ]
    }
   ],
   "source": [
    "print(df_new['x'].isnull().sum())\n",
    "print(df_new['y'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FE time, total_injuries and total_person_count columns\n",
    "df_new[\"time\"]=df_new['incdttm'].dt.strftime('%H:%M')\n",
    "df_new[\"total_injuries\"]=df_new['injuries'] + df_new['seriousinjuries']  + df_new['fatalities']\n",
    "df_new[\"total_person_count\"]=df_new['personcount'] + df_new['pedcount']  + df_new['pedcylcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_emd_crit = (df_new['weather'].isnull() &\n",
    "    df_new['lightcond'].isnull() &\n",
    "    df_new['roadcond'].isnull() &\n",
    "    df_new['collisiontype'].isnull() &\n",
    "    df_new['st_coldesc'].isnull() &\n",
    "    df_new['underinfl'].isnull() &\n",
    "    df_new['inattentionind'].isnull() &\n",
    "    df_new['speeding'].isnull() &\n",
    "    df_new['pedrownotgrnt'].isnull() &\n",
    "    (df_new['vehcount'] == 0))\n",
    "df_new['fe_emd'] = fe_emd_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting incdate to datetime\n",
    "df_new[\"incdate\"] = df_new[\"incdate\"].astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220436, 37)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with Census Areas GEOJSON\n",
    "\n",
    "We can use geopandus to join our collisions dataset to the Census file using our x/y coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>objectid</th>\n",
       "      <th>addrtype</th>\n",
       "      <th>intkey</th>\n",
       "      <th>location</th>\n",
       "      <th>severitycode</th>\n",
       "      <th>severitydesc</th>\n",
       "      <th>collisiontype</th>\n",
       "      <th>personcount</th>\n",
       "      <th>...</th>\n",
       "      <th>speeding</th>\n",
       "      <th>st_colcode</th>\n",
       "      <th>st_coldesc</th>\n",
       "      <th>hitparkedcar</th>\n",
       "      <th>fe_exists</th>\n",
       "      <th>time</th>\n",
       "      <th>total_injuries</th>\n",
       "      <th>total_person_count</th>\n",
       "      <th>fe_emd</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.340472</td>\n",
       "      <td>47.608629</td>\n",
       "      <td>1</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>29598.0</td>\n",
       "      <td>PIKE PL AND PIKE ST</td>\n",
       "      <td>2</td>\n",
       "      <td>Injury Collision</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Vehicle backing hits pedestrian</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>18:36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>POINT (-122.34047 47.60863)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x          y  objectid      addrtype   intkey  \\\n",
       "0 -122.340472  47.608629         1  Intersection  29598.0   \n",
       "\n",
       "              location severitycode      severitydesc collisiontype  \\\n",
       "0  PIKE PL AND PIKE ST            2  Injury Collision    Pedestrian   \n",
       "\n",
       "   personcount  ...  speeding  st_colcode                       st_coldesc  \\\n",
       "0            2  ...       NaN           3  Vehicle backing hits pedestrian   \n",
       "\n",
       "   hitparkedcar  fe_exists   time total_injuries total_person_count fe_emd  \\\n",
       "0             N          1  18:36              1                  3  False   \n",
       "\n",
       "                      geometry  \n",
       "0  POINT (-122.34047 47.60863)  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe that includes a new feature called geometry, which is basically a point made from x & y           \n",
    "gdf_collisions = gpd.GeoDataFrame(df_new, geometry=gpd.points_from_xy(df_new.x, df_new.y))\n",
    "# This will show the newly created geometry geo feature\n",
    "gdf_collisions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>TRACTCE10</th>\n",
       "      <th>GEOID10</th>\n",
       "      <th>NAME10</th>\n",
       "      <th>NAMELSAD10</th>\n",
       "      <th>ACRES_TOTAL</th>\n",
       "      <th>WATER</th>\n",
       "      <th>SHAPE_Length</th>\n",
       "      <th>SHAPE_Area</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>002500</td>\n",
       "      <td>53033002500</td>\n",
       "      <td>25</td>\n",
       "      <td>Census Tract 25</td>\n",
       "      <td>243.219083</td>\n",
       "      <td>0</td>\n",
       "      <td>16442.968402</td>\n",
       "      <td>1.059462e+07</td>\n",
       "      <td>POLYGON ((-122.29602 47.69023, -122.29608 47.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  TRACT TRACTCE10      GEOID10 NAME10       NAMELSAD10  \\\n",
       "0         1   2500    002500  53033002500     25  Census Tract 25   \n",
       "\n",
       "   ACRES_TOTAL  WATER  SHAPE_Length    SHAPE_Area  \\\n",
       "0   243.219083      0  16442.968402  1.059462e+07   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-122.29602 47.69023, -122.29608 47.6...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the Census Tracts Geo file\n",
    "geojson_file = \"../data/Census_Tracts_2010.geojson\"\n",
    "census_tracts = gpd.read_file(geojson_file)\n",
    "census_tracts.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two - a left join means we wont loose records from our collision dataset. within means the x/y pont must be contained within the census polygon\n",
    "df_with_geo = gpd.sjoin(gdf_collisions, census_tracts, how=\"left\", op=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape: (220436, 38)\n",
      "New df shape: (220436, 49)\n"
     ]
    }
   ],
   "source": [
    "# Make sure it was a left join and we didn't loose any records\n",
    "print(\"Original df shape:\", df_new.shape)\n",
    "print(\"New df shape:\", df_with_geo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>objectid</th>\n",
       "      <th>addrtype</th>\n",
       "      <th>intkey</th>\n",
       "      <th>location</th>\n",
       "      <th>severitycode</th>\n",
       "      <th>severitydesc</th>\n",
       "      <th>collisiontype</th>\n",
       "      <th>personcount</th>\n",
       "      <th>...</th>\n",
       "      <th>speeding</th>\n",
       "      <th>st_colcode</th>\n",
       "      <th>st_coldesc</th>\n",
       "      <th>hitparkedcar</th>\n",
       "      <th>fe_exists</th>\n",
       "      <th>time</th>\n",
       "      <th>total_injuries</th>\n",
       "      <th>total_person_count</th>\n",
       "      <th>fe_emd</th>\n",
       "      <th>NAMELSAD10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.340472</td>\n",
       "      <td>47.608629</td>\n",
       "      <td>1</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>29598.0</td>\n",
       "      <td>PIKE PL AND PIKE ST</td>\n",
       "      <td>2</td>\n",
       "      <td>Injury Collision</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Vehicle backing hits pedestrian</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>18:36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Census Tract 81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x          y  objectid      addrtype   intkey  \\\n",
       "0 -122.340472  47.608629         1  Intersection  29598.0   \n",
       "\n",
       "              location severitycode      severitydesc collisiontype  \\\n",
       "0  PIKE PL AND PIKE ST            2  Injury Collision    Pedestrian   \n",
       "\n",
       "   personcount  ...  speeding  st_colcode                       st_coldesc  \\\n",
       "0            2  ...       NaN           3  Vehicle backing hits pedestrian   \n",
       "\n",
       "   hitparkedcar  fe_exists   time total_injuries total_person_count fe_emd  \\\n",
       "0             N          1  18:36              1                  3  False   \n",
       "\n",
       "        NAMELSAD10  \n",
       "0  Census Tract 81  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop un-needed columns\n",
    "df_with_geo.drop(['OBJECTID', 'TRACT', 'TRACTCE10', 'GEOID10', 'NAME10', 'WATER', 'geometry', 'SHAPE_Area', 'SHAPE_Length', 'ACRES_TOTAL', 'index_right', 'SHAPE_Length', 'SHAPE_Area'],axis=1, inplace=True)\n",
    "df_with_geo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_geo.columns = df_with_geo.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with Neighborhood CSV\n",
    "\n",
    "We can merge with this dataset (created using Tableau) which contains the neighborhood for each census group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can pull neighborhood from the csv I created from tableau\n",
    "\n",
    "df_neighborhood = pd.read_csv('../data/location_neighborhood_census_area.csv')\n",
    "df_neighborhood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_geo_neighborhood = pd.merge(df_with_geo, df_neighborhood, on='namelsad10', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>objectid</th>\n",
       "      <th>addrtype</th>\n",
       "      <th>intkey</th>\n",
       "      <th>location</th>\n",
       "      <th>severitycode</th>\n",
       "      <th>severitydesc</th>\n",
       "      <th>collisiontype</th>\n",
       "      <th>personcount</th>\n",
       "      <th>...</th>\n",
       "      <th>st_colcode</th>\n",
       "      <th>st_coldesc</th>\n",
       "      <th>hitparkedcar</th>\n",
       "      <th>fe_exists</th>\n",
       "      <th>time</th>\n",
       "      <th>total_injuries</th>\n",
       "      <th>total_person_count</th>\n",
       "      <th>fe_emd</th>\n",
       "      <th>namelsad10</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.340472</td>\n",
       "      <td>47.608629</td>\n",
       "      <td>1</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>29598.0</td>\n",
       "      <td>PIKE PL AND PIKE ST</td>\n",
       "      <td>2</td>\n",
       "      <td>Injury Collision</td>\n",
       "      <td>Pedestrian</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Vehicle backing hits pedestrian</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>18:36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Census Tract 81</td>\n",
       "      <td>Downtown / Waterfront</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x          y  objectid      addrtype   intkey  \\\n",
       "0 -122.340472  47.608629         1  Intersection  29598.0   \n",
       "\n",
       "              location severitycode      severitydesc collisiontype  \\\n",
       "0  PIKE PL AND PIKE ST            2  Injury Collision    Pedestrian   \n",
       "\n",
       "   personcount  ...  st_colcode                       st_coldesc  \\\n",
       "0            2  ...           3  Vehicle backing hits pedestrian   \n",
       "\n",
       "   hitparkedcar  fe_exists   time  total_injuries total_person_count fe_emd  \\\n",
       "0             N          1  18:36               1                  3  False   \n",
       "\n",
       "        namelsad10           neighborhood  \n",
       "0  Census Tract 81  Downtown / Waterfront  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_geo_neighborhood.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename census area column to something that makes more sense\n",
    "df_with_geo_neighborhood=df_with_geo_neighborhood.rename(columns = {'namelsad10':'census_area'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df shape: (220436, 38)\n",
      "New df shape: (220436, 39)\n"
     ]
    }
   ],
   "source": [
    "# Make sure it was a left join and we didn't loose any records\n",
    "print(\"Original df shape:\", df_new.shape)\n",
    "print(\"New df shape:\", df_with_geo_neighborhood.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dataframe back to what we were using before\n",
    "df_new=df_with_geo_neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing weather with date and census area\n",
    "\n",
    "If that doesn't work, then we will try neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Named Tuple Here so that we can use it in the rest of the notebook\n",
    "DateArea = namedtuple(\"DateArea\", [\"date\", \"area\"])\n",
    "\n",
    "def make_date_area_env_dict(df, date, area, env_condition):\n",
    "    # Creating a dictionary that has a named tuple as the key, basically (date,area) and a dict of environmental (like weather) conditions conditions as the value\n",
    "    # My intent is to count the number of environmental (like weather) conditions for the date/area combination so that the one with the highst count wins\n",
    "\n",
    "    #Only use those records with values for all three features, date, area and environmental (like weather) conditions\n",
    "    df_with_values = df[df[\"incdate\"].notnull() & df[area].notnull() & df[env_condition].notnull()  ]\n",
    "    \n",
    "    # Overall Dictionary Object to track all this informaiton\n",
    "    loc_date_dict = dict()\n",
    "    for idx, row in df_with_values.iterrows():\n",
    "        # This is my date/area tuple\n",
    "        dl = DateArea(date=str(row[date]), area=row[area])\n",
    "        if dl in loc_date_dict.keys():\n",
    "            env_dict = loc_date_dict[dl]\n",
    "            if row[env_condition] in env_dict.keys():\n",
    "                env_dict[row[env_condition]] +=1\n",
    "            else:\n",
    "                env_dict[row[env_condition]]=1\n",
    "                loc_date_dict[dl]=env_dict\n",
    "        else:\n",
    "            env_dict = dict()\n",
    "            env_dict[row[env_condition]]  = 1\n",
    "            loc_date_dict[dl]= env_dict\n",
    "    return loc_date_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary using date, census area for the named tuple (key) and a dictionary of the most common weather conditions for the value\n",
    "dict_date_census_weather = make_date_area_env_dict(df_new, \"incdate\", \"census_area\", \"weather\")\n",
    "count_imputed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37777, 39)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many records do we have where weather is null, but date and census area are not\n",
    "df_no_weather = df_new[df_new[\"incdate\"].notnull() & df_new[\"census_area\"].notnull() & ((df_new[ \"weather\"]==\"Unknown\") | (df_new[ \"weather\"].isnull())) ]\n",
    "df_no_weather.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateArea(date='2004-10-14 00:00:00', area='Census Tract 81')\n",
      "{'Overcast': 1, 'Clear': 1}\n",
      "DateArea(date='2020-01-05 00:00:00', area='Census Tract 12')\n",
      "{'Raining': 1}\n",
      "DateArea(date='2020-02-13 00:00:00', area='Census Tract 109')\n",
      "{'Overcast': 1, 'Clear': 1}\n",
      "DateArea(date='2020-01-21 00:00:00', area='Census Tract 50')\n",
      "{'Overcast': 1}\n",
      "DateArea(date='2004-09-21 00:00:00', area='Census Tract 109')\n",
      "{'Clear': 1}\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 15 items of our imputing dictionary\n",
    "first_5=0\n",
    "for key, value in dict_date_census_weather.items() :\n",
    "    if first_5<5: print(key)\n",
    "    if first_5<5: print(value)    \n",
    "    first_5+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used in our lambda expression below. It will try to fill weather with the most common weather condition for the date/census area combo\n",
    "\n",
    "def find_env_val(dict_env,area_string, date_string, old_val, debug=False):\n",
    "    dl = DateArea(date=str(date_string), area=area_string)\n",
    "    if (str(old_val)==\"nan\" or str(old_val)==\"Unknown\") and dl in dict_env.keys():  \n",
    "        env_dict = dict_env[dl]\n",
    "        # Now we want to find the key of the item in env_dic that has the greatest value (count) and use it to replace our NaN value\n",
    "        # If they all have equal, then the value selected is kind of random (order that it was added to dictionary)\n",
    "        new_val = max(env_dict, key=env_dict.get)\n",
    "        if (debug) and  len(env_dict.keys()) >1: print(f\"Filling in env for {area_string}, and {date_string} with {new_val} using this info {env_dict}\")\n",
    "    else:\n",
    "        new_val = old_val\n",
    "    #print(f\"{area_string}  {newX},{newY}\")\n",
    "    return new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['weather'] = df_new.apply(lambda x: find_env_val(dict_date_census_weather,area_string=x['census_area'],date_string=str(x['incdate']), old_val=x['weather'],debug=False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29251, 39)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_weather = df_new[df_new[\"incdate\"].notnull() & df_new[\"census_area\"].notnull() & ((df_new[ \"weather\"]==\"Unknown\") | (df_new[ \"weather\"].isnull())) ]\n",
    "df_no_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We imputed about a quarter of the null and unknown weather values\n",
    "\n",
    "Now let's try it with neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_date_neighborhood_weather = make_date_area_env_dict(df_new, \"incdate\", \"neighborhood\", \"weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateArea(date='2004-10-14 00:00:00', area='Downtown / Waterfront')\n",
      "{'Overcast': 3, 'Clear': 4}\n",
      "DateArea(date='2020-01-05 00:00:00', area='Northgate')\n",
      "{'Raining': 1}\n",
      "DateArea(date='2020-02-13 00:00:00', area='Georgetown')\n",
      "{'Overcast': 1, 'Clear': 1}\n",
      "DateArea(date='2020-01-21 00:00:00', area='Wallingford')\n",
      "{'Overcast': 1, 'Raining': 1, 'Clear': 1}\n",
      "DateArea(date='2004-09-21 00:00:00', area='Georgetown')\n",
      "{'Clear': 2}\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 15 items of our imputing dictionary\n",
    "first_5=0\n",
    "for key, value in dict_date_neighborhood_weather.items() :\n",
    "    if first_5<5: print(key)\n",
    "    if first_5<5: print(value)    \n",
    "    first_5+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['weather'] = df_new.apply(lambda x: find_env_val(dict_date_neighborhood_weather,area_string=x['neighborhood'],date_string=str(x['incdate']), old_val=x['weather'],debug=False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18403, 39)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_weather = df_new[df_new[\"incdate\"].notnull() & df_new[\"census_area\"].notnull() & ((df_new[ \"weather\"]==\"Unknown\") | (df_new[ \"weather\"].isnull())) ]\n",
    "df_no_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We imputed about a third of the remaining null and unknown weather values\n",
    "\n",
    "Next let's just use date. We can pass a constant value feature for area. We will make one called city that contains only \"seattle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['city']=\"seattle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_date_city_weather = make_date_area_env_dict(df_new, \"incdate\", \"city\", \"weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['weather'] = df_new.apply(lambda x: find_env_val(dict_date_city_weather,area_string=x['city'],date_string=str(x['incdate']), old_val=x['weather'],debug=False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 40)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_weather = df_new[df_new[\"incdate\"].notnull() & df_new[\"census_area\"].notnull() & ((df_new[ \"weather\"]==\"Unknown\") | (df_new[ \"weather\"].isnull())) ]\n",
    "df_no_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have null and unknowns down to such a small amount, let's fill the rest with the most common  value for weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clear\n"
     ]
    }
   ],
   "source": [
    "most_common_value=df_new['weather'].value_counts().index[0]\n",
    "print(most_common_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['weather'].fillna(most_common_value, inplace=True)\n",
    "df_new['weather'].replace(['Unknown'], most_common_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 40)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_weather = df_new[df_new[\"incdate\"].notnull() & df_new[\"census_area\"].notnull() & ((df_new[ \"weather\"]==\"Unknown\") | (df_new[ \"weather\"].isnull())) ]\n",
    "df_no_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can do the same thing for Road Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary using date, census area for the named tuple (key) and a dictionary of the most common weather conditions for the value\n",
    "dict_date_census_roadcond = make_date_area_env_dict(df_new, \"incdate\", \"census_area\", \"roadcond\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29118, 40)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['roadcond'] = df_new.apply(lambda x: find_env_val(dict_date_census_roadcond,area_string=x['census_area'],date_string=str(x['incdate']), old_val=x['roadcond'],debug=False), axis=1)\n",
    "df_no_weather = df_new[df_new[\"incdate\"].notnull() & df_new[\"census_area\"].notnull() & ((df_new[ \"roadcond\"]==\"Unknown\") | (df_new[ \"roadcond\"].isnull())) ]\n",
    "df_no_weather.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_date_neighborhood_roadcond = make_date_area_env_dict(df_new, \"incdate\", \"neighborhood\", \"roadcond\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17539, 40)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['roadcond'] = df_new.apply(lambda x: find_env_val(dict_date_neighborhood_weather,area_string=x['neighborhood'],date_string=str(x['incdate']), old_val=x['roadcond'],debug=False), axis=1)\n",
    "df_no_weather = df_new[df_new[\"incdate\"].notnull() & df_new[\"census_area\"].notnull() & ((df_new[ \"roadcond\"]==\"Unknown\") | (df_new[ \"roadcond\"].isnull())) ]\n",
    "df_no_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_date_city_roadcond = make_date_area_env_dict(df_new, \"incdate\", \"city\", \"roadcond\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 40)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['roadcond'] = df_new.apply(lambda x: find_env_val(dict_date_city_weather,area_string=x['city'],date_string=str(x['incdate']), old_val=x['roadcond'],debug=False), axis=1)\n",
    "df_no_weather = df_new[df_new[\"incdate\"].notnull() & df_new[\"census_area\"].notnull() & ((df_new[ \"roadcond\"]==\"Unknown\") | (df_new[ \"roadcond\"].isnull())) ]\n",
    "df_no_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_value=df_new['roadcond'].value_counts().index[0]\n",
    "df_new['roadcond'].fillna(most_common_value, inplace=True)\n",
    "df_new['roadcond'].replace(['Unknown'], most_common_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, save our new dataframe as a clean (new) version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new.to_csv('../data/collisions_clean_new.csv',index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
